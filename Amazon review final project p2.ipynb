{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-04-27</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-06-13</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568406</th>\n",
       "      <td>568450</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-03-09</td>\n",
       "      <td>will not do without</td>\n",
       "      <td>great sesame chickenthis good better resturant...</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568407</th>\n",
       "      <td>568451</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-03-09</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>disappointed flavor chocolate notes especially...</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.492857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568408</th>\n",
       "      <td>568452</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-02-21</td>\n",
       "      <td>perfect for our maltipoo</td>\n",
       "      <td>stars small give 1015 one training session tri...</td>\n",
       "      <td>-0.021875</td>\n",
       "      <td>0.418750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568409</th>\n",
       "      <td>568453</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-03-13</td>\n",
       "      <td>favorite training and reward treat</td>\n",
       "      <td>best treats training rewarding dog good groomi...</td>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568410</th>\n",
       "      <td>568454</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-05-31</td>\n",
       "      <td>great honey</td>\n",
       "      <td>satisfied product advertised use cereal raw vi...</td>\n",
       "      <td>0.106410</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568411 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId  HelpfulnessNumerator  \\\n",
       "0            1  B001E4KFG0  A3SGXH7AUHU8GW                     1   \n",
       "1            2  B00813GRG4  A1D87F6ZCVE5NK                     0   \n",
       "2            3  B000LQOCH0   ABXLMWJIXXAIN                     1   \n",
       "3            4  B000UA0QIQ  A395BORC6FGVXV                     3   \n",
       "4            5  B006K2ZZ7K  A1UQRSCLF8GW1T                     0   \n",
       "...        ...         ...             ...                   ...   \n",
       "568406  568450  B001EO7N10  A28KG5XORO54AY                     0   \n",
       "568407  568451  B003S1WTCU  A3I8AFVPEE8KI5                     0   \n",
       "568408  568452  B004I613EE  A121AA1GQV751Z                     2   \n",
       "568409  568453  B004I613EE   A3IBEVCTXKNOH                     1   \n",
       "568410  568454  B001LR2CU2  A3LGQPJCZVL9UC                     0   \n",
       "\n",
       "        HelpfulnessDenominator  Score        Time  \\\n",
       "0                            1      5  2011-04-27   \n",
       "1                            0      1  2012-09-07   \n",
       "2                            1      4  2008-08-18   \n",
       "3                            3      2  2011-06-13   \n",
       "4                            0      5  2012-10-21   \n",
       "...                        ...    ...         ...   \n",
       "568406                       0      5  2011-03-09   \n",
       "568407                       0      2  2012-03-09   \n",
       "568408                       2      5  2012-02-21   \n",
       "568409                       1      5  2012-03-13   \n",
       "568410                       0      5  2012-05-31   \n",
       "\n",
       "                                   Summary  \\\n",
       "0                    good quality dog food   \n",
       "1                        not as advertised   \n",
       "2                      delight says it all   \n",
       "3                           cough medicine   \n",
       "4                              great taffy   \n",
       "...                                    ...   \n",
       "568406                 will not do without   \n",
       "568407                        disappointed   \n",
       "568408            perfect for our maltipoo   \n",
       "568409  favorite training and reward treat   \n",
       "568410                         great honey   \n",
       "\n",
       "                                                     Text  polarity  \\\n",
       "0       bought several vitality canned dog food produc...  0.425000   \n",
       "1       product arrived labeled jumbo salted peanutsth...  0.216667   \n",
       "2       confection around centuries light pillowy citr...  0.187000   \n",
       "3       looking secret ingredient robitussin believe f...  0.150000   \n",
       "4       great taffy great price wide assortment yummy ...  0.458333   \n",
       "...                                                   ...       ...   \n",
       "568406  great sesame chickenthis good better resturant...  0.675000   \n",
       "568407  disappointed flavor chocolate notes especially... -0.250000   \n",
       "568408  stars small give 1015 one training session tri... -0.021875   \n",
       "568409  best treats training rewarding dog good groomi...  0.521429   \n",
       "568410  satisfied product advertised use cereal raw vi...  0.106410   \n",
       "\n",
       "        subjectivity  good review  \n",
       "0           0.400000            1  \n",
       "1           0.762963            0  \n",
       "2           0.548000            1  \n",
       "3           0.650000            0  \n",
       "4           0.600000            1  \n",
       "...              ...          ...  \n",
       "568406      0.662500            1  \n",
       "568407      0.492857            0  \n",
       "568408      0.418750            1  \n",
       "568409      0.678571            1  \n",
       "568410      0.653846            1  \n",
       "\n",
       "[568411 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = pd.read_csv('Amazon_review_sentiment_score.csv', index_col=0)\n",
    "new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling: Good reviews + only NOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vitality food products quality product stew me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection centuries pillowy gelatin nuts case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>price assortment yummy taffy delivery taffy lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hair taffy pound bag flavors root beer melon p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>saltwater taffy flavors chewy none candies ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568405</th>\n",
       "      <td>complaint theres use amount spice jar sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568406</th>\n",
       "      <td>sesame chickenthis resturants husband recipes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568408</th>\n",
       "      <td>stars training session train dog ceaser dog tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568409</th>\n",
       "      <td>treats dog calories doggies potatoes wet noses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568410</th>\n",
       "      <td>product use cereal vinegar sweetner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486404 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text\n",
       "0       vitality food products quality product stew me...\n",
       "2       confection centuries pillowy gelatin nuts case...\n",
       "4       price assortment yummy taffy delivery taffy lo...\n",
       "5       hair taffy pound bag flavors root beer melon p...\n",
       "6       saltwater taffy flavors chewy none candies ver...\n",
       "...                                                   ...\n",
       "568405       complaint theres use amount spice jar sister\n",
       "568406      sesame chickenthis resturants husband recipes\n",
       "568408  stars training session train dog ceaser dog tr...\n",
       "568409     treats dog calories doggies potatoes wet noses\n",
       "568410                product use cereal vinegar sweetner\n",
       "\n",
       "[486404 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nouns = pd.DataFrame(new_good_reviews.Text.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_good_reviews= new.loc[new['good review'] ==1]\n",
    "\n",
    "# Create document-term matrix\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv_matrix = cv.fit_transform(data_nouns['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486404, 4)\n",
      "[[0.02326464 0.02401771 0.92964661 0.02307104]\n",
      " [0.19044229 0.01232999 0.01287973 0.78434799]\n",
      " [0.30262062 0.02825773 0.02850944 0.64061221]\n",
      " ...\n",
      " [0.01318844 0.0135063  0.96067125 0.01263401]\n",
      " [0.03125577 0.23445684 0.69857643 0.03571095]\n",
      " [0.04414069 0.64535789 0.04262532 0.2678761 ]]\n"
     ]
    }
   ],
   "source": [
    "# Use LDA for clustering\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=4)\n",
    "\n",
    "# document topic matrix for cv_matrix\n",
    "lda_output = lda.fit_transform(cv_matrix)\n",
    "print(lda_output.shape)\n",
    "print(lda_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 127730)\n",
      "[[0.25002756 0.25000852 1.249854   ... 1.24989451 1.24986764 0.25002337]\n",
      " [0.25003488 0.25001506 0.25005564 ... 0.25004876 0.25005153 1.24829167]\n",
      " [0.25003091 0.25001283 0.25004865 ... 0.2500288  0.250041   0.25166263]\n",
      " [1.24990665 3.24996358 0.25004171 ... 0.25002794 0.25003983 0.25002233]]\n"
     ]
    }
   ],
   "source": [
    "# topics and words matrix\n",
    "topic_word = lda.components_\n",
    "print(topic_word.shape)\n",
    "print(topic_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc5</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc6</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc7</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc8</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic0  Topic1  Topic2  Topic3  topic\n",
       "Doc0    0.02    0.02    0.93    0.02      2\n",
       "Doc1    0.19    0.01    0.01    0.78      3\n",
       "Doc2    0.30    0.03    0.03    0.64      3\n",
       "Doc3    0.14    0.01    0.18    0.67      3\n",
       "Doc4    0.02    0.12    0.02    0.84      3\n",
       "Doc5    0.05    0.05    0.05    0.85      3\n",
       "Doc6    0.04    0.04    0.68    0.24      2\n",
       "Doc7    0.03    0.03    0.90    0.03      2\n",
       "Doc8    0.09    0.72    0.01    0.18      1\n",
       "Doc9    0.01    0.01    0.91    0.06      2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column names\n",
    "topic_names = [\"Topic\" + str(i) for i in range(lda.n_components)]\n",
    "\n",
    "# index names\n",
    "doc_names = [\"Doc\" + str(i) for i in range(len(data_nouns))]\n",
    "\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topic_names, index=doc_names)\n",
    "\n",
    "# get dominant topic for each document\n",
    "topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['topic'] = topic\n",
    "\n",
    "df_document_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic\n",
       "3  150445\n",
       "0  146973\n",
       "2  100467\n",
       "1   88519"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_topic['topic'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25002756 0.25000852 1.249854   ... 1.24989451 1.24986764 0.25002337]\n",
      " [0.25003488 0.25001506 0.25005564 ... 0.25004876 0.25005153 1.24829167]\n",
      " [0.25003091 0.25001283 0.25004865 ... 0.2500288  0.250041   0.25166263]\n",
      " [1.24990665 3.24996358 0.25004171 ... 0.25002794 0.25003983 0.25002233]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>078ounce</th>\n",
       "      <th>092ounce</th>\n",
       "      <th>0ptions</th>\n",
       "      <th>100calories</th>\n",
       "      <th>100cals</th>\n",
       "      <th>100degrees</th>\n",
       "      <th>10calories</th>\n",
       "      <th>10cents</th>\n",
       "      <th>10packs</th>\n",
       "      <th>10years</th>\n",
       "      <th>...</th>\n",
       "      <th>zzzzzs</th>\n",
       "      <th>zzzzzz</th>\n",
       "      <th>zzzzzzzz</th>\n",
       "      <th>zzzzzzzzzzbr</th>\n",
       "      <th>Âµg</th>\n",
       "      <th>Â½inch</th>\n",
       "      <th>Â½ounce</th>\n",
       "      <th>Ã§a</th>\n",
       "      <th>Ã§aykur</th>\n",
       "      <th>Ã®le</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic0</th>\n",
       "      <td>0.250028</td>\n",
       "      <td>0.250009</td>\n",
       "      <td>1.249854</td>\n",
       "      <td>0.250047</td>\n",
       "      <td>0.250012</td>\n",
       "      <td>0.250006</td>\n",
       "      <td>0.267647</td>\n",
       "      <td>0.250016</td>\n",
       "      <td>2.241221</td>\n",
       "      <td>0.281597</td>\n",
       "      <td>...</td>\n",
       "      <td>5.249223</td>\n",
       "      <td>0.250008</td>\n",
       "      <td>0.263456</td>\n",
       "      <td>0.362666</td>\n",
       "      <td>0.250002</td>\n",
       "      <td>0.250002</td>\n",
       "      <td>0.250012</td>\n",
       "      <td>1.249895</td>\n",
       "      <td>1.249868</td>\n",
       "      <td>0.250023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>0.250035</td>\n",
       "      <td>0.250015</td>\n",
       "      <td>0.250056</td>\n",
       "      <td>10.832942</td>\n",
       "      <td>0.250017</td>\n",
       "      <td>0.250007</td>\n",
       "      <td>2.232332</td>\n",
       "      <td>0.253344</td>\n",
       "      <td>0.253854</td>\n",
       "      <td>1.205042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250030</td>\n",
       "      <td>0.250014</td>\n",
       "      <td>0.325747</td>\n",
       "      <td>1.137252</td>\n",
       "      <td>2.249992</td>\n",
       "      <td>1.248971</td>\n",
       "      <td>0.262687</td>\n",
       "      <td>0.250049</td>\n",
       "      <td>0.250052</td>\n",
       "      <td>1.248292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>0.250031</td>\n",
       "      <td>0.250013</td>\n",
       "      <td>0.250049</td>\n",
       "      <td>0.253658</td>\n",
       "      <td>0.253061</td>\n",
       "      <td>0.250007</td>\n",
       "      <td>0.250010</td>\n",
       "      <td>0.250016</td>\n",
       "      <td>0.250007</td>\n",
       "      <td>0.263341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250021</td>\n",
       "      <td>1.240675</td>\n",
       "      <td>0.250006</td>\n",
       "      <td>0.250045</td>\n",
       "      <td>0.250003</td>\n",
       "      <td>0.251025</td>\n",
       "      <td>0.704127</td>\n",
       "      <td>0.250029</td>\n",
       "      <td>0.250041</td>\n",
       "      <td>0.251663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>1.249907</td>\n",
       "      <td>3.249964</td>\n",
       "      <td>0.250042</td>\n",
       "      <td>0.663354</td>\n",
       "      <td>1.246909</td>\n",
       "      <td>1.249980</td>\n",
       "      <td>0.250010</td>\n",
       "      <td>1.246624</td>\n",
       "      <td>0.254918</td>\n",
       "      <td>0.250020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250726</td>\n",
       "      <td>0.259304</td>\n",
       "      <td>1.160791</td>\n",
       "      <td>0.250038</td>\n",
       "      <td>0.250002</td>\n",
       "      <td>0.250002</td>\n",
       "      <td>0.783173</td>\n",
       "      <td>0.250028</td>\n",
       "      <td>0.250040</td>\n",
       "      <td>0.250022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 127730 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        078ounce  092ounce   0ptions  100calories   100cals  100degrees  \\\n",
       "Topic0  0.250028  0.250009  1.249854     0.250047  0.250012    0.250006   \n",
       "Topic1  0.250035  0.250015  0.250056    10.832942  0.250017    0.250007   \n",
       "Topic2  0.250031  0.250013  0.250049     0.253658  0.253061    0.250007   \n",
       "Topic3  1.249907  3.249964  0.250042     0.663354  1.246909    1.249980   \n",
       "\n",
       "        10calories   10cents   10packs   10years  ...    zzzzzs    zzzzzz  \\\n",
       "Topic0    0.267647  0.250016  2.241221  0.281597  ...  5.249223  0.250008   \n",
       "Topic1    2.232332  0.253344  0.253854  1.205042  ...  0.250030  0.250014   \n",
       "Topic2    0.250010  0.250016  0.250007  0.263341  ...  0.250021  1.240675   \n",
       "Topic3    0.250010  1.246624  0.254918  0.250020  ...  0.250726  0.259304   \n",
       "\n",
       "        zzzzzzzz  zzzzzzzzzzbr        Âµg     Â½inch    Â½ounce        Ã§a  \\\n",
       "Topic0  0.263456      0.362666  0.250002  0.250002  0.250012  1.249895   \n",
       "Topic1  0.325747      1.137252  2.249992  1.248971  0.262687  0.250049   \n",
       "Topic2  0.250006      0.250045  0.250003  0.251025  0.704127  0.250029   \n",
       "Topic3  1.160791      0.250038  0.250002  0.250002  0.783173  0.250028   \n",
       "\n",
       "          Ã§aykur       Ã®le  \n",
       "Topic0  1.249868  0.250023  \n",
       "Topic1  0.250052  1.248292  \n",
       "Topic2  0.250041  0.251663  \n",
       "Topic3  0.250040  0.250022  \n",
       "\n",
       "[4 rows x 127730 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topic word matrix\n",
    "print(lda.components_)\n",
    "\n",
    "# topic-word matrix\n",
    "df_topic_words = pd.DataFrame(lda.components_)\n",
    "\n",
    "# column and index\n",
    "df_topic_words.columns = cv.get_feature_names()\n",
    "df_topic_words.index = topic_names\n",
    "\n",
    "df_topic_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>Word 10</th>\n",
       "      <th>Word 11</th>\n",
       "      <th>Word 12</th>\n",
       "      <th>Word 13</th>\n",
       "      <th>Word 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>coffee</td>\n",
       "      <td>tea</td>\n",
       "      <td>flavor</td>\n",
       "      <td>taste</td>\n",
       "      <td>cup</td>\n",
       "      <td>product</td>\n",
       "      <td>price</td>\n",
       "      <td>time</td>\n",
       "      <td>order</td>\n",
       "      <td>drink</td>\n",
       "      <td>use</td>\n",
       "      <td>water</td>\n",
       "      <td>day</td>\n",
       "      <td>amazon</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>water</td>\n",
       "      <td>flavor</td>\n",
       "      <td>taste</td>\n",
       "      <td>product</td>\n",
       "      <td>oil</td>\n",
       "      <td>use</td>\n",
       "      <td>salt</td>\n",
       "      <td>sauce</td>\n",
       "      <td>rice</td>\n",
       "      <td>time</td>\n",
       "      <td>dont</td>\n",
       "      <td>coconut</td>\n",
       "      <td>sugar</td>\n",
       "      <td>ingredients</td>\n",
       "      <td>price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>food</td>\n",
       "      <td>dog</td>\n",
       "      <td>dogs</td>\n",
       "      <td>product</td>\n",
       "      <td>treats</td>\n",
       "      <td>cat</td>\n",
       "      <td>cats</td>\n",
       "      <td>time</td>\n",
       "      <td>treat</td>\n",
       "      <td>day</td>\n",
       "      <td>price</td>\n",
       "      <td>loves</td>\n",
       "      <td>eat</td>\n",
       "      <td>foods</td>\n",
       "      <td>years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>taste</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>flavor</td>\n",
       "      <td>chips</td>\n",
       "      <td>snack</td>\n",
       "      <td>cookies</td>\n",
       "      <td>sugar</td>\n",
       "      <td>product</td>\n",
       "      <td>milk</td>\n",
       "      <td>bars</td>\n",
       "      <td>butter</td>\n",
       "      <td>bag</td>\n",
       "      <td>time</td>\n",
       "      <td>calories</td>\n",
       "      <td>eat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word 0     Word 1  Word 2   Word 3  Word 4   Word 5 Word 6   Word 7  \\\n",
       "Topic 0  coffee        tea  flavor    taste     cup  product  price     time   \n",
       "Topic 1   water     flavor   taste  product     oil      use   salt    sauce   \n",
       "Topic 2    food        dog    dogs  product  treats      cat   cats     time   \n",
       "Topic 3   taste  chocolate  flavor    chips   snack  cookies  sugar  product   \n",
       "\n",
       "        Word 8 Word 9 Word 10  Word 11 Word 12      Word 13  Word 14  \n",
       "Topic 0  order  drink     use    water     day       amazon  morning  \n",
       "Topic 1   rice   time    dont  coconut   sugar  ingredients    price  \n",
       "Topic 2  treat    day   price    loves     eat        foods    years  \n",
       "Topic 3   milk   bars  butter      bag    time     calories      eat  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print top n keywords for each topic\n",
    "def print_topic_words(cv, lda_model, n_words):\n",
    "    words = np.array(cv.get_feature_names())\n",
    "    topic_words = []\n",
    "    # for each topic, we have words weight\n",
    "    for topic_words_weights in lda_model.components_:\n",
    "        top_words = topic_words_weights.argsort()[::-1][:n_words]\n",
    "        topic_words.append(words.take(top_words))\n",
    "    return topic_words\n",
    "\n",
    "topic_keywords = print_topic_words(cv=cv, lda_model=lda, n_words=15)        \n",
    "\n",
    "df_topic_words = pd.DataFrame(topic_keywords)\n",
    "df_topic_words.columns = ['Word '+str(i) for i in range(df_topic_words.shape[1])]\n",
    "df_topic_words.index = ['Topic '+str(i) for i in range(df_topic_words.shape[0])]\n",
    "df_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
